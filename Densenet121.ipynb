{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0R4BgihjGKdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720674189171,"user_tz":-480,"elapsed":2730,"user":{"displayName":"Kek Reviews","userId":"06508242015481338650"}},"outputId":"25ed6dfb-17b6-4275-df3f-4ed6005fa3bc"},"id":"0R4BgihjGKdn","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import scipy\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.losses import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.preprocessing.image import *\n","from tensorflow.keras.utils import *\n","# import pydot\n","\n","from sklearn.metrics import *\n","from sklearn.model_selection import *\n","import tensorflow.keras.backend as K\n","\n","from tqdm import tqdm, tqdm_notebook\n","from colorama import Fore\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from glob import glob\n","from skimage.io import *\n","%config Completer.use_jedi = False\n","import time\n","from sklearn.decomposition import PCA\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import lightgbm as lgb\n","import xgboost as xgb\n","import numpy as np\n","from tqdm import tqdm\n","import cv2\n","import os\n","import shutil\n","import itertools\n","import imutils\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","import plotly.graph_objs as go\n","from plotly.offline import init_notebook_mode, iplot\n","from plotly import tools\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras import layers\n","from keras.models import Model, Sequential\n","from keras.optimizers import Adam, RMSprop\n","from keras.callbacks import EarlyStopping\n","\n","RANDOM_SEED = 123\n","\n","print(\"All modules have been imported\")"],"metadata":{"id":"cXOqD6gwROvM"},"id":"cXOqD6gwROvM","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths\n","data_dir = '/content/drive/My Drive/dataset_16'\n","output_dir_train_test = '/content/drive/My Drive/split_dataset_train_test'\n","\n","# Create output directories for train and test\n","os.makedirs(output_dir_train_test, exist_ok=True)\n","for split in ['train', 'test']:\n","    os.makedirs(os.path.join(output_dir_train_test, split), exist_ok=True)\n","\n","# Split ratios\n","train_ratio = 0.8\n","test_ratio = 0.2\n","\n","# Get class names\n","classes = os.listdir(data_dir)\n","\n","# Create train and test splits\n","for cls in classes:\n","    cls_dir = os.path.join(data_dir, cls)\n","    images = os.listdir(cls_dir)\n","\n","    # Split the images\n","    train, test = train_test_split(images, test_size=test_ratio, random_state=42)\n","\n","    # Create class directories in output splits\n","    for split in ['train', 'test']:\n","        os.makedirs(os.path.join(output_dir_train_test, split, cls), exist_ok=True)\n","\n","    # Move files to respective directories\n","    for split, split_images in zip(['train', 'test'], [train, test]):\n","        for img in split_images:\n","            src = os.path.join(cls_dir, img)\n","            dst = os.path.join(output_dir_train_test, split, cls, img)\n","            shutil.copy(src, dst)\n","\n","print(\"Train and test split completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQDyyQ9aT0eF","outputId":"bfb6ac74-e4e4-4abf-d544-aa876e0e9ec3","executionInfo":{"status":"ok","timestamp":1720674195149,"user_tz":-480,"elapsed":5979,"user":{"displayName":"Kek Reviews","userId":"06508242015481338650"}}},"id":"PQDyyQ9aT0eF","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Train and test split completed.\n"]}]},{"cell_type":"code","execution_count":14,"id":"9b6f7485","metadata":{"execution":{"iopub.execute_input":"2023-11-20T16:17:28.230091Z","iopub.status.busy":"2023-11-20T16:17:28.229690Z","iopub.status.idle":"2023-11-20T16:56:41.019522Z","shell.execute_reply":"2023-11-20T16:56:41.018097Z"},"papermill":{"duration":2352.80774,"end_time":"2023-11-20T16:56:41.033788","exception":false,"start_time":"2023-11-20T16:17:28.226048","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"9b6f7485","outputId":"ab02be97-416c-44a3-f89e-4f863f36171b","executionInfo":{"status":"ok","timestamp":1720675409647,"user_tz":-480,"elapsed":550459,"user":{"displayName":"Kek Reviews","userId":"06508242015481338650"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 384 images belonging to 4 classes.\n","Found 96 images belonging to 4 classes.\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n","                                                                 \n"," global_average_pooling2d_5  (None, 1024)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n"," dense_10 (Dense)            (None, 512)               524800    \n","                                                                 \n"," dense_11 (Dense)            (None, 4)                 2052      \n","                                                                 \n","=================================================================\n","Total params: 7564356 (28.86 MB)\n","Trainable params: 7480708 (28.54 MB)\n","Non-trainable params: 83648 (326.75 KB)\n","_________________________________________________________________\n","Epoch 1/50\n","6/6 [==============================] - 72s 2s/step - loss: 1.0363 - accuracy: 0.5781 - val_loss: 2.5479 - val_accuracy: 0.3438\n","Epoch 2/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.4774 - accuracy: 0.8542 - val_loss: 7.8680 - val_accuracy: 0.2500\n","Epoch 3/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.3261 - accuracy: 0.9062 - val_loss: 25.6302 - val_accuracy: 0.2500\n","Epoch 4/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.1249 - accuracy: 0.9505 - val_loss: 23.7742 - val_accuracy: 0.2500\n","Epoch 5/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0678 - accuracy: 0.9766 - val_loss: 30.0397 - val_accuracy: 0.2604\n","Epoch 6/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.1809 - accuracy: 0.9557 - val_loss: 27.8274 - val_accuracy: 0.3021\n","Epoch 7/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 33.8375 - val_accuracy: 0.2604\n","Epoch 8/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 19.5467 - val_accuracy: 0.2604\n","Epoch 9/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 29.6977 - val_accuracy: 0.2500\n","Epoch 10/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0502 - accuracy: 0.9766 - val_loss: 24.5468 - val_accuracy: 0.2500\n","Epoch 11/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0778 - accuracy: 0.9661 - val_loss: 12.5513 - val_accuracy: 0.2812\n","Epoch 12/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.0915 - accuracy: 0.9766 - val_loss: 6.3092 - val_accuracy: 0.4167\n","Epoch 13/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0415 - accuracy: 0.9896 - val_loss: 7.7372 - val_accuracy: 0.3646\n","Epoch 14/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0331 - accuracy: 0.9844 - val_loss: 4.2585 - val_accuracy: 0.5312\n","Epoch 15/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 4.4186 - val_accuracy: 0.5521\n","Epoch 16/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.0254 - accuracy: 0.9948 - val_loss: 2.6915 - val_accuracy: 0.6042\n","Epoch 17/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 5.3546 - val_accuracy: 0.5208\n","Epoch 18/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 5.8529 - val_accuracy: 0.5625\n","Epoch 19/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 7.9297 - val_accuracy: 0.5208\n","Epoch 20/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0496 - accuracy: 0.9870 - val_loss: 5.2678 - val_accuracy: 0.5833\n","Epoch 21/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0330 - accuracy: 0.9948 - val_loss: 8.9291 - val_accuracy: 0.4479\n","Epoch 22/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0484 - accuracy: 0.9870 - val_loss: 5.3842 - val_accuracy: 0.4583\n","Epoch 23/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0564 - accuracy: 0.9792 - val_loss: 7.1709 - val_accuracy: 0.5104\n","Epoch 24/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 1.7024 - val_accuracy: 0.7604\n","Epoch 25/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0364 - accuracy: 0.9870 - val_loss: 2.9441 - val_accuracy: 0.6250\n","Epoch 26/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.8613 - val_accuracy: 0.3333\n","Epoch 27/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0569 - accuracy: 0.9844 - val_loss: 2.9362 - val_accuracy: 0.5729\n","Epoch 28/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.8292 - val_accuracy: 0.7812\n","Epoch 29/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 4.2205 - val_accuracy: 0.6042\n","Epoch 30/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0714 - accuracy: 0.9740 - val_loss: 3.3602 - val_accuracy: 0.6146\n","Epoch 31/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0685 - accuracy: 0.9870 - val_loss: 7.8497 - val_accuracy: 0.3854\n","Epoch 32/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.1446 - accuracy: 0.9635 - val_loss: 3.4032 - val_accuracy: 0.5104\n","Epoch 33/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0913 - accuracy: 0.9844 - val_loss: 3.9538 - val_accuracy: 0.5521\n","Epoch 34/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.1004 - accuracy: 0.9583 - val_loss: 3.6060 - val_accuracy: 0.5521\n","Epoch 35/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0920 - accuracy: 0.9688 - val_loss: 2.0657 - val_accuracy: 0.7083\n","Epoch 36/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 4.1395 - val_accuracy: 0.5833\n","Epoch 37/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0267 - accuracy: 0.9948 - val_loss: 2.2030 - val_accuracy: 0.6458\n","Epoch 38/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 2.6386 - val_accuracy: 0.6146\n","Epoch 39/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0484 - accuracy: 0.9818 - val_loss: 2.9355 - val_accuracy: 0.4896\n","Epoch 40/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0231 - accuracy: 0.9896 - val_loss: 3.6170 - val_accuracy: 0.4688\n","Epoch 41/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 5.5832 - val_accuracy: 0.3750\n","Epoch 42/50\n","6/6 [==============================] - 10s 2s/step - loss: 0.0164 - accuracy: 0.9922 - val_loss: 16.9944 - val_accuracy: 0.2500\n","Epoch 43/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 24.1685 - val_accuracy: 0.2604\n","Epoch 44/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 25.1252 - val_accuracy: 0.2604\n","Epoch 45/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 19.8764 - val_accuracy: 0.2604\n","Epoch 46/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 13.4984 - val_accuracy: 0.2604\n","Epoch 47/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 12.2275 - val_accuracy: 0.3958\n","Epoch 48/50\n","6/6 [==============================] - 8s 1s/step - loss: 0.0187 - accuracy: 0.9896 - val_loss: 11.6033 - val_accuracy: 0.4167\n","Epoch 49/50\n","6/6 [==============================] - 9s 1s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 8.8327 - val_accuracy: 0.3854\n","Epoch 50/50\n","6/6 [==============================] - 9s 2s/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 6.6355 - val_accuracy: 0.4479\n","2/2 [==============================] - 1s 124ms/step - loss: 6.6355 - accuracy: 0.4479\n","Validation Loss: 6.635500431060791, Validation Accuracy: 0.4479166567325592\n","2/2 [==============================] - 2s 213ms/step\n","              precision    recall  f1-score   support\n","\n","      glioma       0.50      0.04      0.08        24\n","  meningioma       0.33      0.42      0.37        24\n","     notumor       0.25      0.67      0.36        24\n","   pituitary       0.00      0.00      0.00        24\n","\n","    accuracy                           0.28        96\n","   macro avg       0.27      0.28      0.20        96\n","weighted avg       0.27      0.28      0.20        96\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["train_datasets = \"/content/drive/My Drive/split_dataset_train_test/train\"\n","test_datasets = \"/content/drive/My Drive/split_dataset_train_test/test\"\n","\n","batch_size = 64\n","image_size = (224, 224)  # DenseNet121 expects input size as (224, 224, 3)\n","\n","def load_data(dir_path, img_size=(100,100)):\n","    \"\"\"\n","    Load resized images as np.arrays to workspace\n","    \"\"\"\n","    X = []\n","    y = []\n","    i = 0\n","    labels = dict()\n","    for path in tqdm(sorted(os.listdir(dir_path))):\n","        if not path.startswith('.'):\n","            labels[i] = path\n","            for file in os.listdir(dir_path + path):\n","                if not file.startswith('.'):\n","                    img = cv2.imread(dir_path + path + '/' + file)\n","                    X.append(img)\n","                    y.append(i)\n","            i += 1\n","    X = np.array(X)\n","    y = np.array(y)\n","    print(f'{len(X)} images loaded from {dir_path} directory.')\n","    return X, y, labels\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.figure(figsize = (6,6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        thresh = cm.max() / 2.\n","    cm = np.round(cm,2)\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.show()\n","\n","X_train, y_train, labels = load_data(train_datasets, image_size)\n","X_test, y_test, _ = load_data(test_datasets, image_size)\n","\n","def crop_imgs(set_name, add_pixels_value=0):\n","    \"\"\"\n","    Finds the extreme points on the image and crops the rectangular out of them\n","    \"\"\"\n","    set_new = []\n","    for img in set_name:\n","        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","        # threshold the image, then perform a series of erosions +\n","        # dilations to remove any small regions of noise\n","        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n","        thresh = cv2.erode(thresh, None, iterations=2)\n","        thresh = cv2.dilate(thresh, None, iterations=2)\n","        # find contours in thresholded image, then grab the largest one\n","        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cnts = imutils.grab_contours(cnts)\n","        c = max(cnts, key=cv2.contourArea)\n","\n","        # find the extreme points\n","        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","        extRight = tuple(c[c[:, :, 0].argmax()][0])\n","        extTop = tuple(c[c[:, :, 1].argmin()][0])\n","        extBot = tuple(c[c[:, :, 1].argmax()][0])\n","\n","        ADD_PIXELS = add_pixels_value\n","        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n","        set_new.append(new_img)\n","\n","    return np.array(set_new)\n","\n","import imutils\n","img = cv2.imread('./content/drive/My Drive/split_dataset_train_test/pituitary/Tr-pi_0509.jpg')\n","img = cv2.resize(\n","            img,\n","            dsize=image_size,\n","            interpolation=cv2.INTER_CUBIC\n","        )\n","gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","# threshold the image, then perform a series of erosions +\n","# dilations to remove any small regions of noise\n","thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n","thresh = cv2.erode(thresh, None, iterations=2)\n","thresh = cv2.dilate(thresh, None, iterations=2)\n","\n","# find contours in thresholded image, then grab the largest one\n","cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","cnts = imutils.grab_contours(cnts)\n","c = max(cnts, key=cv2.contourArea)\n","# find the extreme points\n","extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","extRight = tuple(c[c[:, :, 0].argmax()][0])\n","extTop = tuple(c[c[:, :, 1].argmin()][0])\n","extBot = tuple(c[c[:, :, 1].argmax()][0])\n","\n","# add contour on the image\n","img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n","\n","# add extreme points\n","img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n","img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n","img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n","img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n","\n","# crop\n","ADD_PIXELS = 0\n","new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n","\n","plt.figure(figsize=(15,6))\n","plt.subplot(141)\n","plt.imshow(img)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 1. Get the original image')\n","plt.subplot(142)\n","plt.imshow(img_cnt)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 2. Find the biggest contour')\n","plt.subplot(143)\n","plt.imshow(img_pnt)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 3. Find the extreme points')\n","plt.subplot(144)\n","plt.imshow(new_img)\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Step 4. Crop the image')\n","plt.show()\n","\n","X_train_crop = crop_imgs(set_name=X_train)\n","X_test_crop = crop_imgs(set_name=X_test)\n","\n","def plot_samples(X, y, labels_dict, n=50):\n","    \"\"\"\n","    Creates a gridplot for desired number of images (n) from the specified set\n","    \"\"\"\n","    for index in range(len(labels_dict)):\n","        imgs = X[np.argwhere(y == index)][:n]\n","        j = 10\n","        i = int(n/j)\n","\n","        plt.figure(figsize=(15,6))\n","        c = 1\n","        for img in imgs:\n","            plt.subplot(i,j,c)\n","            plt.imshow(img[0])\n","\n","            plt.xticks([])\n","            plt.yticks([])\n","            c += 1\n","        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n","        plt.show()\n","\n","plot_samples(X_train_crop, y_train, labels, 30)\n","\n","def preprocess_imgs(set_name, img_size):\n","    set_new = []\n","    for img in set_name:\n","        img = cv2.resize(\n","            img,\n","            dsize=img_size,\n","            interpolation=cv2.INTER_CUBIC\n","        )\n","        set_new.append(preprocess_input(img))\n","    return np.array(set_new)"]},{"cell_type":"code","source":["def preprocess_imgs(set_name, img_size):\n","    set_new = []\n","    for img in set_name:\n","        img = cv2.resize(\n","            img,\n","            dsize=img_size,\n","            interpolation=cv2.INTER_CUBIC\n","        )\n","        set_new.append(preprocess_input(img))\n","    return np.array(set_new)\n","\n","X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=image_size)\n","X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=image_size)\n","plot_samples(X_train_prep, y_train, labels, 30)"],"metadata":{"id":"zaMf9yUxT073"},"id":"zaMf9yUxT073","execution_count":null,"outputs":[]},{"cell_type":"code","source":["demo_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.05,\n","    height_shift_range=0.05,\n","    rescale=1./255,\n","    shear_range=0.05,\n","    brightness_range=[0.1, 1.5],\n","    horizontal_flip=True,\n","    vertical_flip=True\n",")\n","\n","os.mkdir('preview')\n","x = X_train_crop[0]\n","x = x.reshape((1,) + x.shape)\n","\n","i = 0\n","for batch in demo_datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='aug_img', save_format='jpg'):\n","    i += 1\n","    if i > 20:\n","        break\n","\n","plt.imshow(X_train_crop[0])\n","plt.xticks([])\n","plt.yticks([])\n","plt.title('Original Image')\n","plt.show()\n","\n","plt.figure(figsize=(15,6))\n","\n","i = 1\n","for img in os.listdir('preview/'):\n","    img = cv2.cv2.imread('preview/' + img)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.subplot(3,7,i)\n","    plt.imshow(img)\n","    plt.xticks([])\n","    plt.yticks([])\n","    i += 1\n","    if i > 3*7:\n","        break\n","plt.suptitle('Augemented Images')\n","plt.show()\n"],"metadata":{"id":"esclmmv8UEb-"},"id":"esclmmv8UEb-","execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_DIR = 'TRAIN_CROP/'\n","VAL_DIR = 'VAL_CROP/'\n","train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    brightness_range=[0.5, 1.5],\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    preprocessing_function=preprocess_input\n",")\n","\n","test_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    color_mode='rgb',\n","    target_size=image_size,\n","    batch_size=32,\n","    class_mode='binary',\n","    seed=RANDOM_SEED\n",")\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    VAL_DIR,\n","    color_mode='rgb',\n","    target_size=IMG_SIZE,\n","    batch_size=16,\n","    class_mode='binary',\n","    seed=RANDOM_SEED\n",")\n"],"metadata":{"id":"6LLD0YPRURBD"},"id":"6LLD0YPRURBD","execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_Neural_Net= DenseNet169(input_shape=(224,224,3), weights='imagenet', include_top=False)\n","model=Sequential()\n","model.add(base_Neural_Net)\n","model.add(Flatten())\n","model.add(BatchNormalization())\n","model.add(Dense(256,kernel_initializer='he_uniform'))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1,activation='sigmoid'))\n","\n","for layer in base_Neural_Net.layers:\n","    layer.trainable = False\n","\n","\n","model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy' , 'AUC']\n",")\n","model.summary()\n","\n","EPOCHS = 30\n","es = EarlyStopping(\n","    monitor='val_acc',\n","    mode='max',\n","    patience=6\n",")\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=50,\n","    epochs=EPOCHS,\n","    validation_data=validation_generator,\n","    validation_steps=25,\n","    callbacks=[es]\n",")"],"metadata":{"id":"sy6Z9vcEU342"},"id":"sy6Z9vcEU342","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(X_train_prep)\n","predictions = [1 if x>0.5 else 0 for x in predictions]\n","\n","accuracy = accuracy_score(y_train, predictions)\n","print('Train Accuracy = %.2f' % accuracy)\n","\n","confusion_mtx = confusion_matrix(y_train, predictions)\n","cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"],"metadata":{"id":"y7OOvr4iWBU5"},"id":"y7OOvr4iWBU5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(X_val_prep)\n","predictions = [1 if x>0.5 else 0 for x in predictions]\n","\n","accuracy = accuracy_score(y_val, predictions)\n","print('Val Accuracy = %.2f' % accuracy)\n","\n","confusion_mtx = confusion_matrix(y_val, predictions)\n","cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"],"metadata":{"id":"nRy7fksIWEPA"},"id":"nRy7fksIWEPA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# validate on test set\n","predictions = model.predict(X_test_prep)\n","predictions = [1 if x>0.5 else 0 for x in predictions]\n","\n","accuracy = accuracy_score(y_test, predictions)\n","print('Test Accuracy = %.2f' % accuracy)\n","\n","confusion_mtx = confusion_matrix(y_test, predictions)\n","cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)"],"metadata":{"id":"TgU2SIEhWG0B"},"id":"TgU2SIEhWG0B","execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":672377,"sourceId":1183165,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":2359.591596,"end_time":"2023-11-20T16:56:44.759540","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-20T16:17:25.167944","version":"2.4.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}